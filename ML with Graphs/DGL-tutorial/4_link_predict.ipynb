{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI1nSRrns1R-"
      },
      "source": [
        "# 그래프 뉴럴 네트워크를 사용한 링크 예측\n",
        "\n",
        "GNN은 그래프 데이터에 대한 많은 머신러닝 task를 해결하는 데 강력한 툴입니다.  \n",
        "이 튜토리얼에서는, 링크 예측을 위해 GNN을 사용하는 기본적인 워크플로우를 배울 수 있습니다.  \n",
        "여기서 Zachery의 카라테 클럽 그래프를 다시 사용합니다. 하지만, 이번에는 두 멤버 사이의 관계를 예측하는 작업을 시도해 봅니다.\n",
        "\n",
        "이 튜토리얼에서, 다음을 배울 수 있습니다.\n",
        "* 링크 예측을 위한 학습/테스트 셋을 준비하는 방법\n",
        "* GNN 기반 링크 예측 모델을 구축하는 법\n",
        "* 모델을 학습하고, 그 결과를 검증하는 법\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTn1AyXrt9jY",
        "outputId": "d4daae16-98f2-427b-90eb-d5b87c244d6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.0.1-cp39-cp39-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgl) (3.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9E0qumdws1SE",
        "outputId": "a5b7b559-218e-45d2-a30f-325ddd5aca0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9BqxRSxs1SI"
      },
      "source": [
        "## 그래프와 피처 로드\n",
        "\n",
        "최근 튜토리얼 [세션](./3_gnn.ipynb)에 이어, Zachery의 카라테 클럽 그래프를 불러들여 노드 임베딩을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_zachery():\n",
        "    nodes_data = pd.read_csv('https://github.com/myeonghak/DGL-tutorial/raw/master/data/nodes.csv')\n",
        "    edges_data = pd.read_csv('https://github.com/myeonghak/DGL-tutorial/raw/master/data/edges.csv')\n",
        "    src = edges_data['Src'].to_numpy()\n",
        "    dst = edges_data['Dst'].to_numpy()\n",
        "    g = dgl.graph((src, dst))\n",
        "    club = nodes_data['Club'].to_list()\n",
        "    # Convert to categorical integer values with 0 for 'Mr. Hi', 1 for 'Officer'.\n",
        "    club = torch.tensor([c == 'Officer' for c in club]).long()\n",
        "    # We can also convert it to one-hot encoding.\n",
        "    club_onehot = F.one_hot(club)\n",
        "    g.ndata.update({'club' : club, 'club_onehot' : club_onehot})\n",
        "    return g"
      ],
      "metadata": {
        "id": "TJB3PGQJ1umZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gA93gkIjs1SJ",
        "outputId": "8425b9f6-40e8-41ba-ead4-e77b0b22c62d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=34, num_edges=156,\n",
            "      ndata_schemes={'club': Scheme(shape=(), dtype=torch.int64), 'club_onehot': Scheme(shape=(2,), dtype=torch.int64)}\n",
            "      edata_schemes={})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0698, -0.2622, -0.2227, -0.3751,  0.1616],\n",
              "        [-0.3672,  0.0380,  0.3421, -0.0670,  0.1739],\n",
              "        [ 0.2855, -0.1088, -0.3463, -0.0254, -0.2204],\n",
              "        [-0.0246, -0.0744, -0.1450,  0.3751,  0.1368],\n",
              "        [-0.0945, -0.1112,  0.1822,  0.0420,  0.1027],\n",
              "        [ 0.3401,  0.2707, -0.3557,  0.2078, -0.1940],\n",
              "        [ 0.1406, -0.2580,  0.2936, -0.0913,  0.2470],\n",
              "        [-0.1162,  0.1044,  0.2185,  0.2882, -0.2329],\n",
              "        [ 0.3779, -0.0421,  0.3420,  0.1483, -0.0385],\n",
              "        [ 0.2712, -0.1888,  0.0721,  0.0260, -0.0025],\n",
              "        [-0.3603,  0.0250,  0.1849, -0.3890, -0.0703],\n",
              "        [-0.0005, -0.2812, -0.2989, -0.0581,  0.2052],\n",
              "        [ 0.1325, -0.3779,  0.0980,  0.3426,  0.3353],\n",
              "        [ 0.1958,  0.1409, -0.1899,  0.3841, -0.2240],\n",
              "        [ 0.0669,  0.1885,  0.2104,  0.1104,  0.0632],\n",
              "        [ 0.0920,  0.2643, -0.2170, -0.2410, -0.0280],\n",
              "        [-0.2029,  0.0568,  0.1467, -0.3873, -0.0691],\n",
              "        [ 0.1742,  0.3289, -0.1823, -0.0210,  0.0541],\n",
              "        [ 0.1701,  0.0474, -0.0615, -0.0184,  0.3193],\n",
              "        [ 0.2794, -0.1337, -0.1469, -0.3223,  0.2531],\n",
              "        [-0.0364,  0.1561,  0.3819,  0.0528, -0.3295],\n",
              "        [-0.0164, -0.1228, -0.1356, -0.0173, -0.1027],\n",
              "        [ 0.2841,  0.3018,  0.3780,  0.0119, -0.1549],\n",
              "        [-0.1023, -0.1571, -0.0293,  0.1842,  0.2258],\n",
              "        [ 0.1955,  0.1084, -0.3719,  0.2254,  0.2620],\n",
              "        [-0.1639, -0.1816,  0.2120,  0.3019, -0.2768],\n",
              "        [-0.1472,  0.0467, -0.2024,  0.1775,  0.1771],\n",
              "        [-0.2449, -0.3685,  0.0915, -0.3413,  0.1354],\n",
              "        [ 0.3357,  0.3834,  0.1701,  0.0881,  0.3809],\n",
              "        [ 0.3614, -0.2316, -0.3639, -0.2006,  0.2746],\n",
              "        [-0.0863,  0.2093, -0.2784,  0.2718,  0.2474],\n",
              "        [-0.3674,  0.3897, -0.3603, -0.3202, -0.3626],\n",
              "        [-0.1983, -0.2894, -0.2729,  0.1322,  0.2886],\n",
              "        [ 0.1565, -0.3817, -0.3196,  0.0952, -0.2534]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#from tutorial_utils import load_zachery\n",
        "\n",
        "# ----------- 0. load graph -------------- #\n",
        "g = load_zachery()\n",
        "print(g)\n",
        "\n",
        "# ----------- 1. node features -------------- #\n",
        "node_embed = nn.Embedding(g.number_of_nodes(), 5) # 각 노드는 5차원의 임베딩을 가지고 있습니다.\n",
        "inputs = node_embed.weight                         # 노드 피처로써 이 임베딩 가중치를 사용합니다.\n",
        "nn.init.xavier_uniform_(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnDPHE_Vs1SK"
      },
      "source": [
        "## 학습/테스트 셋을 준비 합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRS58aZbs1SL"
      },
      "source": [
        "일반적으로, 링크 예측 데이터셋은 *positive*와 *negative* 엣지라는 2 타입의 엣지를 포함하고 있습니다.  \n",
        "positive 엣지는 보통 그래프 내에 이미 존재하는 엣지로부터 가져옵니다.  \n",
        "이 예제에서, 50개의 임의의 엣지를 골라 테스트에 사용하고 나머지는 학습에 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ESL7TFDds1SM"
      },
      "outputs": [],
      "source": [
        "# 학습과 테스트를 위해 엣지 셋을 분할합니다.\n",
        "u, v = g.edges() # u : source node, v : destination node\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)# random permutation 0부터 155까지의 순열을 섞어\n",
        "# 2:1비율\n",
        "test_pos_u, test_pos_v = u[eids[:50]], v[eids[:50]] # 앞부분 50개를 test set으로\n",
        "train_pos_u, train_pos_v = u[eids[50:]], v[eids[50:]]# 나머지를 train set으로 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uKaicTXs1SN"
      },
      "source": [
        "negative 엣지의 수가 크기때문에, 보통 샘플링 해주는 것이 좋습니다.   \n",
        "적절한 negative 샘플링 알고리즘을 선택하는 방법에 대한 문제는 널리 연구되는 주제로, 이 튜토리얼의 범위를 벗어납니다.  \n",
        "우리의 예제 그래프는 상당히 작기 때문에(노드 34개뿐), 모든 결측 엣지를 나열해 임의로 50개를 테스트에 사용하고, 150개를 학습에 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UGf4Kcuws1SO"
      },
      "outputs": [],
      "source": [
        "# 모든 negative 엣지를 찾아 학습과 테스트용으로 분할\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(34)\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "neg_eids = np.random.choice(len(neg_u), 200)\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:50]], neg_v[neg_eids[:50]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[50:]], neg_v[neg_eids[50:]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J259e8gPs1SP"
      },
      "source": [
        "Put positive and negative edges together and form training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WuKWhGeLs1SQ"
      },
      "outputs": [],
      "source": [
        "# Create training set.\n",
        "train_u = torch.cat([torch.as_tensor(train_pos_u), torch.as_tensor(train_neg_u)])\n",
        "train_v = torch.cat([torch.as_tensor(train_pos_v), torch.as_tensor(train_neg_v)])\n",
        "train_label = torch.cat([torch.zeros(len(train_pos_u)), torch.ones(len(train_neg_u))])\n",
        "\n",
        "# Create testing set.\n",
        "test_u = torch.cat([torch.as_tensor(test_pos_u), torch.as_tensor(test_neg_u)])\n",
        "test_v = torch.cat([torch.as_tensor(test_pos_v), torch.as_tensor(test_neg_v)])\n",
        "test_label = torch.cat([torch.zeros(len(test_pos_u)), torch.ones(len(test_neg_u))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGEpqdJYs1SS"
      },
      "source": [
        "## GraphSAGE 모델 정의하기\n",
        "\n",
        "우리의 모델은 2개 레이어로 구성되어 있는데, 각각 새로운 노드 표현(representation)을 이웃의 정보를 통합함으로써 계산합니다.  \n",
        "수식은 다음과 같습니다.  ([이전 튜토리얼](./3_gnn.ipynb)과 약간 다릅니다.)\n",
        "\n",
        "$$\n",
        "h_{\\mathcal{N}(v)}^k\\leftarrow \\text{AGGREGATE}_k\\{h_u^{k-1},\\forall u\\in\\mathcal{N}(v)\\}\n",
        "$$\n",
        "\n",
        "$$\n",
        "h_v^k\\leftarrow \\text{ReLU}\\left(W^k\\cdot \\text{CONCAT}(h_v^{k-1}, h_{\\mathcal{N}(v)}^k) \\right)\n",
        "$$\n",
        "\n",
        "DGL은 많은 유명한 이웃 통합(neighbor aggregation) 모듈의 구현체를 제공합니다. 모두 쉽게 한 줄의 코드로 호출하여 사용할 수 있습니다.  \n",
        "지원되는 모델의 전체 리스트는 [graph convolution modules](https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.conv)에서 보실 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번엔 activation function으로 ReLU를 사용함함"
      ],
      "metadata": {
        "id": "BKQEev6a3Rdg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "esqtoLBzs1ST"
      },
      "outputs": [],
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# 2개의 레이어를 가진 GraphSAGE 모델 구축\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "    \n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "    \n",
        "# 주어진 차원의 모델 생성\n",
        "# 인풋 레이어 차원: 5, 노드 임베딩\n",
        "# 히든 레이어 차원: 16 -> 굳이 줄이지 않고 16차원 사용용\n",
        "net = GraphSAGE(5, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwhSPxJMs1SU"
      },
      "source": [
        "그 뒤, 모델을 아래의 손실함수를 사용해 최적화합니다.\n",
        "\n",
        "$$\n",
        "\\hat{y}_{u\\sim v} = \\sigma(h_u^T h_v)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = -\\sum_{u\\sim v\\in \\mathcal{D}}\\left( y_{u\\sim v}\\log(\\hat{y}_{u\\sim v}) + (1-y_{u\\sim v})\\log(1-\\hat{y}_{u\\sim v})) \\right)\n",
        "$$\n",
        "\n",
        "기본적으로, 모델은 엣지의 두 끝지점(노드)의 표현을 내적함으로써 각 엣지에 대한 점수를 계산합니다.  \n",
        "그 뒤 타겟 y가 0 혹은 1인 binary cross entropy loss를 계산합니다. 여기서 0 혹은 1은 해당 엣지가 positive인지 아닌지를 나타냅니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross entropy 정의 : positive와 negative 결과 취합"
      ],
      "metadata": {
        "id": "UzzDJyiN3iIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WcCILywNs1SV",
        "outputId": "707694cf-be82-4a04-eefc-7a71553d3978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 1.6950342655181885\n",
            "In epoch 5, loss: 0.6657971739768982\n",
            "In epoch 10, loss: 0.5298175811767578\n",
            "In epoch 15, loss: 0.4615646302700043\n",
            "In epoch 20, loss: 0.4157412648200989\n",
            "In epoch 25, loss: 0.3844454288482666\n",
            "In epoch 30, loss: 0.3574339747428894\n",
            "In epoch 35, loss: 0.3341028094291687\n",
            "In epoch 40, loss: 0.3168826699256897\n",
            "In epoch 45, loss: 0.30252447724342346\n",
            "In epoch 50, loss: 0.2887336313724518\n",
            "In epoch 55, loss: 0.2739599049091339\n",
            "In epoch 60, loss: 0.2589886486530304\n",
            "In epoch 65, loss: 0.24078720808029175\n",
            "In epoch 70, loss: 0.2217487394809723\n",
            "In epoch 75, loss: 0.20026949048042297\n",
            "In epoch 80, loss: 0.1786074936389923\n",
            "In epoch 85, loss: 0.15957871079444885\n",
            "In epoch 90, loss: 0.1371162384748459\n",
            "In epoch 95, loss: 0.11415942758321762\n"
          ]
        }
      ],
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# 이 경우, 학습 루프의 손실\n",
        "optimizer = torch.optim.Adam(itertools.chain(net.parameters(), node_embed.parameters()), lr=0.01)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    logits = net(g, inputs)\n",
        "    pred = torch.sigmoid((logits[train_u] * logits[train_v]).sum(dim=1))\n",
        "    \n",
        "    # 손실 계산\n",
        "    loss = F.binary_cross_entropy(pred, train_label)\n",
        "    \n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    all_logits.append(logits.detach())\n",
        "    \n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, loss: {}'.format(e, loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlKEMFXMs1SW"
      },
      "source": [
        "결과를 확인해 봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ppcdnhUKs1SW",
        "outputId": "e6413e1d-3b22-4c18-9c96-59acd4ab85ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8\n"
          ]
        }
      ],
      "source": [
        "# ----------- 5. check results ------------------------ #\n",
        "pred = torch.sigmoid((logits[test_u] * logits[test_v]).sum(dim=1))\n",
        "print('Accuracy', ((pred >= 0.5) == test_label).sum().item() / len(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq4hz1SHs1SX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}