{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRePh2TC4k2u"
      },
      "source": [
        "# GPU를 사용해 학습 가속하기\n",
        "\n",
        "이번 튜토리얼에서, 다음을 배우게 됩니다.\n",
        "\n",
        "* 그래프와 피처 데이터를 GPU로 복사하는 방법\n",
        "* GNN 모델을 GPU 위에 학습하는 방법\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check cuda version\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLxFSRfdrDLm",
        "outputId": "b57646de-60fb-44f0-8671-29a1c0eb24c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dgl-cu110"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQfdZ2KWrT2Z",
        "outputId": "8cb297d0-dc82-47a9-bbd7-ca3fe943d1e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl-cu110\n",
            "  Downloading dgl_cu110-0.6.1-cp39-cp39-manylinux1_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgl-cu110) (3.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgl-cu110) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgl-cu110) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from dgl-cu110) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl-cu110) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl-cu110) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl-cu110) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl-cu110) (2.0.12)\n",
            "Installing collected packages: dgl-cu110\n",
            "Successfully installed dgl-cu110-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IHDcfJdB4k2z",
        "outputId": "3ff56a44-dec8-494d-f069-0ab4d0244074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ],
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz56Fxxv4k23"
      },
      "source": [
        "## 그래프와 피처 데이터를 GPU에 복사\n",
        "\n",
        "먼저 이전 세션에 사용한 Zachery의 카라테 클럽 그래프와 노드 라벨를 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_zachery():\n",
        "    nodes_data = pd.read_csv('https://github.com/myeonghak/DGL-tutorial/raw/master/data/nodes.csv')\n",
        "    edges_data = pd.read_csv('https://github.com/myeonghak/DGL-tutorial/raw/master/data/edges.csv')\n",
        "    src = edges_data['Src'].to_numpy()\n",
        "    dst = edges_data['Dst'].to_numpy()\n",
        "    g = dgl.graph((src, dst))\n",
        "    club = nodes_data['Club'].to_list()\n",
        "    # Convert to categorical integer values with 0 for 'Mr. Hi', 1 for 'Officer'.\n",
        "    club = torch.tensor([c == 'Officer' for c in club]).long()\n",
        "    # We can also convert it to one-hot encoding.\n",
        "    club_onehot = F.one_hot(club)\n",
        "    g.ndata.update({'club' : club, 'club_onehot' : club_onehot})\n",
        "    return g"
      ],
      "metadata": {
        "id": "Pp-W1dEasCEg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J21dXyjS4k25",
        "outputId": "30a41231-4b18-44d9-83fe-77ba2c107722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=34, num_edges=156,\n",
            "      ndata_schemes={'club': Scheme(shape=(), dtype=torch.int64), 'club_onehot': Scheme(shape=(2,), dtype=torch.int64)}\n",
            "      edata_schemes={})\n"
          ]
        }
      ],
      "source": [
        "#from tutorial_utils import load_zachery\n",
        "\n",
        "# ----------- 0. load graph -------------- #\n",
        "g = load_zachery()\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6jah-dx4k26"
      },
      "source": [
        "이제 그래프와 모든 그래프의 피처 데이터는 CPU에 적재되어 있습니다. `to` API를 사용해 다른 연산장치로 복사해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dshL1uS74k27",
        "outputId": "0d6359ab-7285-4815-9d49-d0368ad152d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device: cpu\n",
            "New device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "print('Current device:', g.device)\n",
        "g = g.to('cuda:0')\n",
        "print('New device:', g.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOJNh8no4k28"
      },
      "source": [
        "Verify that features are also copied to GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7l-dQrSi4k29",
        "outputId": "1a6ae319-4b2a-4ca3-8126-6aefa4fa03af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(g.ndata['club'].device)\n",
        "print(g.ndata['club_onehot'].device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MePfMt2a4k2-"
      },
      "source": [
        "## GNN 모델을 GPU에 생성하기\n",
        "\n",
        "이 스텝은 CNN이나 RNN 모델을 GPU에 생성하는 것과 같습니다.  \n",
        "PyTorch에서, `to` API를 사용해 이를 수행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o_EEBZgM4k2-",
        "outputId": "1cddeb95-c199-43ff-a1f1-e9edeafeb42b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0512,  0.1105, -0.3783, -0.3138, -0.0261],\n",
              "        [-0.3697, -0.0519, -0.1647, -0.1861,  0.1402],\n",
              "        [ 0.2388, -0.2833, -0.2277, -0.2604,  0.1609],\n",
              "        [-0.0015, -0.1800, -0.0628, -0.3103, -0.2310],\n",
              "        [ 0.3619,  0.2736, -0.0693, -0.3774, -0.3645],\n",
              "        [ 0.0130, -0.3617, -0.0439,  0.0451, -0.3525],\n",
              "        [-0.3158, -0.1318, -0.2977,  0.3522, -0.3351],\n",
              "        [-0.2375, -0.1198, -0.0169,  0.2250,  0.3449],\n",
              "        [-0.0928, -0.2827, -0.2498, -0.2203,  0.1367],\n",
              "        [-0.1820,  0.0456, -0.2142,  0.2698, -0.0167],\n",
              "        [ 0.2905,  0.2195,  0.1550,  0.0767, -0.0195],\n",
              "        [-0.0318, -0.2610,  0.2051,  0.3398,  0.2931],\n",
              "        [-0.1404,  0.0501,  0.0910,  0.1598, -0.3840],\n",
              "        [-0.0805,  0.3095,  0.2779, -0.2318,  0.2361],\n",
              "        [ 0.2033, -0.3618, -0.0139, -0.3582,  0.1457],\n",
              "        [ 0.2887,  0.1012,  0.1058, -0.1653, -0.3283],\n",
              "        [ 0.3444,  0.1393, -0.2606,  0.0716,  0.3879],\n",
              "        [ 0.2936,  0.2358, -0.0281,  0.2174,  0.0892],\n",
              "        [-0.0882, -0.2472,  0.0948, -0.0359,  0.1923],\n",
              "        [ 0.1683,  0.1908,  0.0547,  0.1287,  0.1897],\n",
              "        [ 0.3176, -0.3094, -0.2684,  0.2942, -0.2382],\n",
              "        [ 0.1283, -0.3728,  0.0871, -0.3920, -0.3311],\n",
              "        [ 0.3666,  0.0309, -0.1351, -0.0553, -0.3164],\n",
              "        [ 0.3051, -0.3880, -0.2555, -0.3070, -0.1402],\n",
              "        [ 0.1206,  0.1265,  0.0077,  0.3526,  0.3103],\n",
              "        [ 0.0099, -0.1019, -0.3679,  0.1491, -0.3872],\n",
              "        [-0.2350,  0.2124,  0.3542,  0.1269,  0.0207],\n",
              "        [ 0.0689, -0.0774, -0.1961, -0.1605, -0.1847],\n",
              "        [ 0.0102,  0.1992, -0.1200, -0.0471,  0.0319],\n",
              "        [ 0.0150,  0.1053, -0.2998, -0.1092, -0.0465],\n",
              "        [-0.3462, -0.1991,  0.1710,  0.3099, -0.1587],\n",
              "        [ 0.1614,  0.3310, -0.1575, -0.3922, -0.2192],\n",
              "        [ 0.2725,  0.1327, -0.1578,  0.1337,  0.1839],\n",
              "        [ 0.0788,  0.3859,  0.0086, -0.0825, -0.3391]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# ----------- 1. node features -------------- #\n",
        "node_embed = nn.Embedding(g.number_of_nodes(), 5)  # 각 노드는 5차원의 임베딩을 가지고 있습니다.\n",
        "# Copy node embeddings to GPU\n",
        "node_embed = node_embed.to('cuda:0')\n",
        "inputs = node_embed.weight                         # 노드 피처로써 이 임베딩 가중치를 사용합니다.\n",
        "nn.init.xavier_uniform_(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23WbMzB4k3A"
      },
      "source": [
        "커뮤니티의 라벨은 `'club'`이라는 노드 피처에 저장되어 있습니다. (0은 instructor의 커뮤니티, 1은 club president의 커뮤니티).  \n",
        "오로지 0과 33번 노드에만 라벨링 되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qmxt0qNz4k3A",
        "outputId": "902a01a5-dce1-47f2-93c4-6dfc900f5da7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels tensor([0, 1], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "labels = g.ndata['club']\n",
        "labeled_nodes = [0, 33]\n",
        "print('Labels', labels[labeled_nodes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS_NhNRS4k3C"
      },
      "source": [
        "## GraphSAGE 모델 정의하기\n",
        "\n",
        "우리의 모델은 2개 레이어로 구성되어 있는데, 각각 새로운 노드 표현(representation)을 이웃의 정보를 통합함으로써 계산합니다.  \n",
        "수식은 다음과 같습니다.  \n",
        "\n",
        "\n",
        "$$\n",
        "h_{\\mathcal{N}(v)}^k\\leftarrow \\text{AGGREGATE}_k\\{h_u^{k-1},\\forall u\\in\\mathcal{N}(v)\\}\n",
        "$$\n",
        "\n",
        "$$\n",
        "h_v^k\\leftarrow \\sigma\\left(W^k\\cdot \\text{CONCAT}(h_v^{k-1}, h_{\\mathcal{N}(v)}^k) \\right)\n",
        "$$\n",
        "\n",
        "DGL은 많은 유명한 이웃 통합(neighbor aggregation) 모듈의 구현체를 제공합니다. 모두 쉽게 한 줄의 코드로 호출하여 사용할 수 있습니다.  \n",
        "지원되는 모델의 전체 리스트는 [graph convolution modules](https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.conv)에서 보실 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nwk9C9XN4k3D"
      },
      "outputs": [],
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# 2개의 레이어를 가진 GraphSAGE 모델 구축\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, num_classes, 'mean')\n",
        "    \n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "    \n",
        "# 주어진 차원의 모델 생성\n",
        "# 인풋 레이어 차원: 5, 노드 임베딩\n",
        "# 히든 레이어 차원: 16\n",
        "# 아웃풋 레이어 차원: 2, 클래스가 2개 있기 때문, 0과 1\n",
        "\n",
        "net = GraphSAGE(5, 16, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnnbZ0xb4k3E"
      },
      "source": [
        "네트워크를 GPU에 복사함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qXgapx9e4k3E"
      },
      "outputs": [],
      "source": [
        "net = net.to('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uxp1EWWj4k3F",
        "outputId": "d4346693-59d8-4066-c6e6-d28a5b70d26e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 0.7012346386909485\n",
            "In epoch 5, loss: 0.3282551169395447\n",
            "In epoch 10, loss: 0.1220165491104126\n",
            "In epoch 15, loss: 0.03706631809473038\n",
            "In epoch 20, loss: 0.01077364757657051\n",
            "In epoch 25, loss: 0.0036164354532957077\n",
            "In epoch 30, loss: 0.001538184704259038\n",
            "In epoch 35, loss: 0.0008244633208960295\n",
            "In epoch 40, loss: 0.0005310544511303306\n",
            "In epoch 45, loss: 0.0003911085077561438\n",
            "In epoch 50, loss: 0.0003160333726555109\n",
            "In epoch 55, loss: 0.00027152185793966055\n",
            "In epoch 60, loss: 0.0002429189917165786\n",
            "In epoch 65, loss: 0.00022313484805636108\n",
            "In epoch 70, loss: 0.00020829649292863905\n",
            "In epoch 75, loss: 0.00019649715977720916\n",
            "In epoch 80, loss: 0.00018648550030775368\n",
            "In epoch 85, loss: 0.00017766558448784053\n",
            "In epoch 90, loss: 0.00016956074978224933\n",
            "In epoch 95, loss: 0.00016193260671570897\n"
          ]
        }
      ],
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# 이 경우, 학습 루프의 손실\n",
        "\n",
        "optimizer = torch.optim.Adam(itertools.chain(net.parameters(), node_embed.parameters()), lr=0.01)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    logits = net(g, inputs)\n",
        "    \n",
        "    # 손실 계산\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    loss = F.nll_loss(logp[labeled_nodes], labels[labeled_nodes])\n",
        "    \n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    all_logits.append(logits.detach())\n",
        "    \n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, loss: {}'.format(e, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rs3jmwRp4k3H",
        "outputId": "f13edcb9-3a24-439b-9b30-aab6a0391c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8529411764705882\n"
          ]
        }
      ],
      "source": [
        "# ----------- 5. check results ------------------------ #\n",
        "pred = torch.argmax(logits, axis=1)\n",
        "print('Accuracy', (pred == labels).sum().item() / len(pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6PNeoy14k3H"
      },
      "source": [
        "**한 GPU 메모리에 그래프와 피처 데이터를 적재할 수 없으면 어떻게 하나요?** \n",
        "\n",
        "* GNN을 천제 그래프에 대해 수행하는 대신에, 몇몇 subgraph에 대해 수행해 수렴시켜보세요.\n",
        "* 다른 샘플을 다른 GPU에 올림으로써 더 빠른 가속을 경험해 보세요.\n",
        "* 그래프를 여러 머신에 분할하여 분산된 형태로 학습시켜보세요.\n",
        "\n",
        "추후에 이러한 방법론을 각각 살펴볼 예정입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tYre7Rc4k3I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}