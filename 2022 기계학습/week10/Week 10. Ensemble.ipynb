{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff74942",
   "metadata": {},
   "source": [
    "# 00. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf9b03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4424, 37)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graduate    2209\n",
       "Dropout     1421\n",
       "Enrolled     794\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "df = pds.read_csv(os.path.join('../files/Week 10. data-student.csv')\n",
    "                  , delimiter=';'\n",
    "                 )\n",
    "print(df.shape)\n",
    "Y = df['Target']\n",
    "X = df.drop(columns = ['Target'], axis = 1)\n",
    "\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0de964",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.apply(lambda x: 0 if x == 'Graduate' else (1 if x == 'Enrolled' else 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab35607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marital status 6 int64\n",
      "Application mode 18 int64\n",
      "Application order 8 int64\n",
      "Course 17 int64\n",
      "Daytime/evening attendance\t 2 int64\n",
      "Previous qualification 17 int64\n",
      "Previous qualification (grade) 101 float64\n",
      "Nacionality 21 int64\n",
      "Mother's qualification 29 int64\n",
      "Father's qualification 34 int64\n",
      "Mother's occupation 32 int64\n",
      "Father's occupation 46 int64\n",
      "Admission grade 620 float64\n",
      "Displaced 2 int64\n",
      "Educational special needs 2 int64\n",
      "Debtor 2 int64\n",
      "Tuition fees up to date 2 int64\n",
      "Gender 2 int64\n",
      "Scholarship holder 2 int64\n",
      "Age at enrollment 46 int64\n",
      "International 2 int64\n",
      "Curricular units 1st sem (credited) 21 int64\n",
      "Curricular units 1st sem (enrolled) 23 int64\n",
      "Curricular units 1st sem (evaluations) 35 int64\n",
      "Curricular units 1st sem (approved) 23 int64\n",
      "Curricular units 1st sem (grade) 805 float64\n",
      "Curricular units 1st sem (without evaluations) 11 int64\n",
      "Curricular units 2nd sem (credited) 19 int64\n",
      "Curricular units 2nd sem (enrolled) 22 int64\n",
      "Curricular units 2nd sem (evaluations) 30 int64\n",
      "Curricular units 2nd sem (approved) 20 int64\n",
      "Curricular units 2nd sem (grade) 786 float64\n",
      "Curricular units 2nd sem (without evaluations) 10 int64\n",
      "Unemployment rate 10 float64\n",
      "Inflation rate 9 float64\n",
      "GDP 10 float64\n"
     ]
    }
   ],
   "source": [
    "for c, sdf in X.iteritems():\n",
    "    print(c, len(np.unique(sdf)), sdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de1c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous qualification (grade) 101 float64\n",
      "Admission grade 620 float64\n",
      "Curricular units 1st sem (grade) 805 float64\n",
      "Curricular units 2nd sem (grade) 786 float64\n",
      "Unemployment rate 10 float64\n",
      "Inflation rate 9 float64\n",
      "GDP 10 float64\n"
     ]
    }
   ],
   "source": [
    "for c, sdf in X.iteritems():\n",
    "    if sdf.dtypes == np.float64:\n",
    "        print(c, len(np.unique(sdf)), sdf.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d8adb",
   "metadata": {},
   "source": [
    "# 01. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f929ef03",
   "metadata": {},
   "source": [
    "\n",
    "1. Remove columns\n",
    "\n",
    "   데이터의 열에 단 하나의 값만 존재한다면, 해당 열의 사용 여부에 대해 고민해야 합니다.  \n",
    "   버섯 데이터셋에 이런 경우가 존재한다면 제거하도록 코드를 작성하겠습니다.\n",
    "\n",
    "\n",
    "2. Categorical columns\n",
    "\n",
    "   데이터셋에 discrete value가 소수만 존재하는 경우, 동시에 value 간의 우위를 논하기 어려운 경우입니다.  \n",
    "   One-hot encoding은 해당 데이터를 처리하기 위해 자주 사용되는 방법 중 하나입니다.\n",
    "\n",
    "\n",
    "3. Numerical columns\n",
    "\n",
    "   데이터의 열에 수치형 변수가 들어가 있는 경우입니다.  \n",
    "   거리 기반의 기계학습 모델들을 활용하는 경우, numerical variable에 대한 normalization을 반드시 고려해줘야 합니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50587b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a952a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remove_columns = []\n",
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "\n",
    "# 열별로 데이터 탐색 진행 = column을 순차대로 탐색하는 것과 같음\n",
    "for c, t in X.iteritems():\n",
    "    \n",
    "    # 데이터가 만약 수치형이 아니라면 categorical에 대해 고민해 볼 필요 있음\n",
    "    if t.dtype != np.float64:\n",
    "        \n",
    "        # 데이터에 존재하는 고윳값 갯수 계산\n",
    "        n_unique = len(t.unique())\n",
    "        \n",
    "        # 고윳값이 단 하나라면 필요 없는 데이터일수 있음\n",
    "        if n_unique == 1:\n",
    "            remove_columns.append(c)\n",
    "            \n",
    "        # 아니라면 categorical preprocessing 적용\n",
    "        else:\n",
    "            categorical_columns.append(c)\n",
    "            \n",
    "    # 수치형이라면, 수치형에 대한 preprocessing 적용 \n",
    "    else:\n",
    "        numerical_columns.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7301d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 9, 'B': 1, 'C': 2, 'E': 8, 'L': 4, 'K': 5, 'T': 10, 'J': 7}\n",
      "{'A': 9, 'B': 1, 'C': 2, 'E': 8, 'L': 4, 'K': 5, 'T': 10, 'J': 7}\n"
     ]
    }
   ],
   "source": [
    "# dictionary comprehension\n",
    "\n",
    "'''\n",
    "위 아래 두 코드는 똑같이 작동하는 코드입니다.\n",
    "'''\n",
    "\n",
    "D = dict()\n",
    "L = 'ABCELKTJEAT'\n",
    "for n, s in enumerate(L):\n",
    "    D[s] = n\n",
    "print(D)\n",
    "\n",
    "D = {s:n for n, s in enumerate(L)}\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752d2686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marital status 6 int64\n",
      "Application mode 18 int64\n",
      "Application order 8 int64\n",
      "Course 17 int64\n",
      "Daytime/evening attendance\t 2 int64\n",
      "Previous qualification 17 int64\n",
      "Nacionality 21 int64\n",
      "Mother's qualification 29 int64\n",
      "Father's qualification 34 int64\n",
      "Mother's occupation 32 int64\n",
      "Father's occupation 46 int64\n",
      "Displaced 2 int64\n",
      "Educational special needs 2 int64\n",
      "Debtor 2 int64\n",
      "Tuition fees up to date 2 int64\n",
      "Gender 2 int64\n",
      "Scholarship holder 2 int64\n",
      "Age at enrollment 46 int64\n",
      "International 2 int64\n",
      "Curricular units 1st sem (credited) 21 int64\n",
      "Curricular units 1st sem (enrolled) 23 int64\n",
      "Curricular units 1st sem (evaluations) 35 int64\n",
      "Curricular units 1st sem (approved) 23 int64\n",
      "Curricular units 1st sem (without evaluations) 11 int64\n",
      "Curricular units 2nd sem (credited) 19 int64\n",
      "Curricular units 2nd sem (enrolled) 22 int64\n",
      "Curricular units 2nd sem (evaluations) 30 int64\n",
      "Curricular units 2nd sem (approved) 20 int64\n",
      "Curricular units 2nd sem (without evaluations) 10 int64\n"
     ]
    }
   ],
   "source": [
    "for c, sdf in X.iteritems():\n",
    "    if sdf.dtypes == np.int64:\n",
    "        print(c, len(np.unique(sdf)), sdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda6cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_transform(df, cs):\n",
    "    return_list = []\n",
    "    numeric_columns = []\n",
    "    \n",
    "    for c in cs:\n",
    "        # categorical column list 'cs' 중 하나인 \"c\"에 존재하는 고윳 값들 전부에 대응되는 숫자 생성\n",
    "        unique_values = {i : n for n,i in enumerate(sorted(df[c].unique()))}\n",
    "        \n",
    "        # lambda를 활용하여 dataframe의 c column에 존재하는 각 값들을 숫자로 변환\n",
    "        num_df = df[c].apply(lambda x: unique_values[x])\n",
    "        \n",
    "        # 만약 고윳값이 2개인 경우, 1열로 표현 가능 ( e.g. 0 - 1 or -1 - 1 )\n",
    "        if len(unique_values) == 2:\n",
    "            return_list.append(num_df.values.reshape(-1,1))\n",
    "        \n",
    "        # 만약 고윳값이 3개 이상인 경우, 고윳값 갯수만큼의 열을 활용한 one-hot encoding을 수행해야 함.\n",
    "        # 단 너무 많은 고윳값의 경우 discrete numerical variables일 수 있기 때문에, one-hot encoding에서 제외함\n",
    "        elif len(unique_values) < 10:\n",
    "            return_list.append(np.eye(len(unique_values))[num_df])\n",
    "\n",
    "        # 제외한 column들을 return하여 numerical preprocessing을 적용\n",
    "        else:\n",
    "            numeric_columns.append(c)\n",
    "    return np.concatenate(return_list, 1), numeric_columns\n",
    "\n",
    "\n",
    "def num_transform(df, cs):\n",
    "    num_df = df[cs].copy().values\n",
    "    \n",
    "    #열별 평균으로 빼고 분산을 1로 변환하는 Standard scaling (a.k.a z-scaling)\n",
    "    num_df = (df[cs].values - num_df.mean(0)) / (num_df.std(0) + 1e-10)\n",
    "    return num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b07bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " ['Marital status',\n",
       "  'Application mode',\n",
       "  'Application order',\n",
       "  'Course',\n",
       "  'Daytime/evening attendance\\t',\n",
       "  'Previous qualification',\n",
       "  'Nacionality',\n",
       "  \"Mother's qualification\",\n",
       "  \"Father's qualification\",\n",
       "  \"Mother's occupation\",\n",
       "  \"Father's occupation\",\n",
       "  'Displaced',\n",
       "  'Educational special needs',\n",
       "  'Debtor',\n",
       "  'Tuition fees up to date',\n",
       "  'Gender',\n",
       "  'Scholarship holder',\n",
       "  'Age at enrollment',\n",
       "  'International',\n",
       "  'Curricular units 1st sem (credited)',\n",
       "  'Curricular units 1st sem (enrolled)',\n",
       "  'Curricular units 1st sem (evaluations)',\n",
       "  'Curricular units 1st sem (approved)',\n",
       "  'Curricular units 1st sem (without evaluations)',\n",
       "  'Curricular units 2nd sem (credited)',\n",
       "  'Curricular units 2nd sem (enrolled)',\n",
       "  'Curricular units 2nd sem (evaluations)',\n",
       "  'Curricular units 2nd sem (approved)',\n",
       "  'Curricular units 2nd sem (without evaluations)'],\n",
       " ['Previous qualification (grade)',\n",
       "  'Admission grade',\n",
       "  'Curricular units 1st sem (grade)',\n",
       "  'Curricular units 2nd sem (grade)',\n",
       "  'Unemployment rate',\n",
       "  'Inflation rate',\n",
       "  'GDP'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_columns, categorical_columns, numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "990ca8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_arr, add_numerical_columns = cat_transform(df, categorical_columns)\n",
    "\n",
    "num_arr = num_transform(df, numerical_columns + add_numerical_columns)\n",
    "\n",
    "df_arr = np.concatenate([num_arr, cat_arr], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf01c1",
   "metadata": {},
   "source": [
    "# 02. DT - regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "178a78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ss_kfold_fn(data_x, data_y, scaling = True):\n",
    "    kf = StratifiedKFold()\n",
    "    for n, (train_idx, valid_idx) in enumerate(kf.split(data_x, data_y)):\n",
    "        \n",
    "        scaler_x = StandardScaler()\n",
    "        \n",
    "        if scaling:\n",
    "            \n",
    "            train_x = scaler_x.fit_transform(data_x[train_idx])\n",
    "            valid_x = scaler_x.transform(data_x[valid_idx])\n",
    "            \n",
    "        else:\n",
    "            train_x = data_x[train_idx]\n",
    "            valid_x = data_x[valid_idx]\n",
    "\n",
    "        train_y = data_y[train_idx]\n",
    "        valid_y = data_y[valid_idx]\n",
    "        \n",
    "        yield [\n",
    "            [train_x, train_y],\n",
    "            [valid_x, valid_y]\n",
    "        ], (scaler_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45b19236",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ss_kfold_fn(df_arr, Y.values, False)\n",
    "\n",
    "((train_x, train_y), (valid_x, valid_y)), s = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34aceee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def dt_pred(ccpa):    \n",
    "    dt = DecisionTreeClassifier(ccp_alpha = ccpa)\n",
    "    dt.fit(train_x, train_y)\n",
    "    return dt.predict_proba(valid_x)\n",
    "\n",
    "ccp_range = np.arange(0, 3e-2, 1e-4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(3)\n",
    "    logits = pool.map(dt_pred, ccp_range)\n",
    "    pool.close()\n",
    "    pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53442ced",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/2746315742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mroc_aucs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ovr'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logits' is not defined"
     ]
    }
   ],
   "source": [
    "accs = [accuracy_score(valid_y, l.argmax(1)) for l in logits]\n",
    "\n",
    "f1s = [f1_score(valid_y, l.argmax(1), average = 'macro') for l in logits]\n",
    "\n",
    "roc_aucs = [roc_auc_score(valid_y, l, multi_class = 'ovr') for l in logits]\n",
    "\n",
    "fig,ax = plt.subplots(1,1, figsize = (10, 3))\n",
    "\n",
    "ax.plot(ccp_range, accs)\n",
    "ax.plot(ccp_range, f1s)\n",
    "ax.plot(ccp_range, roc_aucs)\n",
    "\n",
    "ax.legend(['ACC','F1','AUC'])\n",
    "\n",
    "ax.set_title('Max score: ACC: {:.2f}% F1: {:.2f}% AUC: {:.4f}'.format(max(accs)*100, max(f1s)*100, max(roc_aucs)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f23cc1",
   "metadata": {},
   "source": [
    "# 03. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07255bff",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    "    <img \n",
    "       src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLHXE3%2Fbtqw7cWPjSb%2FxKoaC8GrwfFbAN2CMraSw0%2Fimg.png\" \n",
    "       width=\"700\">\n",
    "</figure>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb8444",
   "metadata": {},
   "source": [
    "### 03-1. Split bagging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_idx_and_col(x, y, bagging_ratio = .7):\n",
    "    indexes, variables = x.shape\n",
    "    \n",
    "    bagging_indexes = int(indexes * bagging_ratio)\n",
    "    bagging_variables = int(variables * bagging_ratio)\n",
    "    \n",
    "    random_idx = np.random.choice(range(indexes), bagging_indexes)\n",
    "    random_col = np.random.choice(range(variables), bagging_variables)\n",
    "    return (x[random_idx][:,random_col], y[random_idx]), (random_idx, random_col)  # part of full dataframe x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61497b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train, sub_loc = randomize_idx_and_col(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc66459",
   "metadata": {},
   "source": [
    "### 03-2. Create bagging models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generate(\n",
    "    knn_neighbors = [3,7,13,21],\n",
    "    knn_repeats = 3,\n",
    "    dt_repeats = 30,\n",
    "):\n",
    "    models = []\n",
    "    \n",
    "    for n_neighbors in knn_neighbors:\n",
    "        models.extend([KNC(n_neighbors = n_neighbors, n_jobs = -1, weights = 'distance')] * knn_repeats)\n",
    "    models.extend([DecisionTreeClassifier()] * dt_repeats)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model_generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061db148",
   "metadata": {},
   "source": [
    "### 03-3.  Learning models with Bagging process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b57706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:03<00:00, 10.80it/s]\n"
     ]
    }
   ],
   "source": [
    "logits = []\n",
    "for model in tqdm(models):\n",
    "    sub_train, sub_loc = randomize_idx_and_col(train_x, train_y)\n",
    "    model.fit(*sub_train)\n",
    "    logits.append(model.predict_proba(valid_x[:, sub_loc[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b68466",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/3534497625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mroc_aucs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ovr'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/3534497625.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mroc_aucs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ovr'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "accs = [accuracy_score(valid_y, l.argmax(1)) for l in logits]\n",
    "\n",
    "f1s = [f1_score(valid_y, l.argmax(1), average = 'macro') for l in logits]\n",
    "\n",
    "roc_aucs = [roc_auc_score(valid_y, l, multi_class = 'ovr') for l in logits]\n",
    "\n",
    "fig,ax = plt.subplots(1,1, figsize = (10, 3))\n",
    "\n",
    "ax.plot(accs)\n",
    "ax.plot(f1s)\n",
    "ax.plot(roc_aucs)\n",
    "\n",
    "ax.legend(['ACC','F1','AUC'])\n",
    "\n",
    "\n",
    "avg_acc = accuracy_score(valid_y, np.array(logits).mean(0).argmax(-1))\n",
    "avg_f1  = f1_score(valid_y, np.array(logits).mean(0).argmax(-1), average = 'macro')\n",
    "avg_roc = roc_auc_score(valid_y, np.array(logits).mean(0), multi_class = 'ovr')\n",
    "\n",
    "ax.set_title('Max score: ACC: {:.2f}% F1: {:.2f}% AUC: {:.4f}'.format(avg_acc*100, avg_f1*100, avg_roc))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788acf0",
   "metadata": {},
   "source": [
    "# 04. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (1.6.2)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.9.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.23.2)\r\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier as HGBC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = HGBC(max_iter=1000)\n",
    "\n",
    "ensemble.fit(train_x, train_y)\n",
    "\n",
    "ensemble_logit = ensemble.predict_proba(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dbeed0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.09128\n",
      "[1000]\tvalidation_0-mlogloss:0.56241\n",
      "[1775]\tvalidation_0-mlogloss:0.58966\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators = 100000,\n",
    "    gpu_id = 0,\n",
    "    tree_method = 'gpu_hist',\n",
    "    learning_rate = 1e-2\n",
    ")\n",
    "xgb.fit(train_x, train_y, eval_set = [(valid_x, valid_y)], verbose = 1000, early_stopping_rounds = 1000)\n",
    "\n",
    "xgb_logit = xgb.predict_proba(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81c728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg. DT   ACC: 70.17% F1: 62.96% AUC: 0.7976\n",
      "Bagging   ACC: 76.38% F1: 66.95% AUC: 0.8748\n",
      "Ensemble  ACC: 75.59% F1: 67.25% AUC: 0.8796\n",
      "XGBoost   ACC: 77.40% F1: 70.02% AUC: 0.8883\n"
     ]
    }
   ],
   "source": [
    "ensemble_acc = accuracy_score(valid_y, ensemble_logit.argmax(-1))\n",
    "ensemble_f1 = f1_score(valid_y, ensemble_logit.argmax(-1), average = 'macro')\n",
    "ensemble_auc = roc_auc_score(valid_y, ensemble_logit, multi_class = 'ovr')\n",
    "\n",
    "xgb_acc = accuracy_score(valid_y, xgb_logit.argmax(-1))\n",
    "xgb_f1 = f1_score(valid_y, xgb_logit.argmax(-1), average = 'macro')\n",
    "xgb_auc = roc_auc_score(valid_y, xgb_logit, multi_class = 'ovr')\n",
    "\n",
    "print('Reg. DT   ACC: {:.2f}% F1: {:.2f}% AUC: {:.4f}'.format(max(accs)*100, max(f1s)*100, max(roc_aucs)))\n",
    "print('Bagging   ACC: {:.2f}% F1: {:.2f}% AUC: {:.4f}'.format(avg_acc*100, avg_f1*100, avg_roc))\n",
    "print('Ensemble  ACC: {:.2f}% F1: {:.2f}% AUC: {:.4f}'.format(ensemble_acc*100, ensemble_f1*100, ensemble_auc))\n",
    "print('XGBoost   ACC: {:.2f}% F1: {:.2f}% AUC: {:.4f}'.format(xgb_acc*100, xgb_f1*100, xgb_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ddd09a61b2c7e17c2a62d168de822f4c67e18302d8919811a53cdcb291e5f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
