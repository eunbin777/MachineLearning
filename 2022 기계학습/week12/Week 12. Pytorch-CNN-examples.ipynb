{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf3a068",
   "metadata": {},
   "source": [
    "# 01. Vary types of the Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99abb0f",
   "metadata": {},
   "source": [
    "<img src = https://imgur.com/s4HMZ3V.png width = 700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65a8cc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src = https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/120px-PyTorch_logo_black.svg.png width = 150>\n",
    "\n",
    "[PyTorch](https://en.wikipedia.org/wiki/PyTorch) is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella.  \n",
    "\n",
    "It is free and open-source software released under the modified BSD license.  \n",
    "\n",
    "Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.\n",
    "\n",
    "[Installation Guide](https://pytorch.org/get-started/previous-versions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.MNIST(\n",
    "    root=\".\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\".\",\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = training_data[4]\n",
    "plt.imshow(img)\n",
    "plt.title('Target: ' + str(target))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b3564",
   "metadata": {},
   "source": [
    "## 01-01. Pytorch dataloader\n",
    "\n",
    "Pytorch dataloader는 batch 단위의 데이터를 torch의 data type으로 관리하는 것을 도와주는 클래스입니다. \n",
    "\n",
    "먼저, torch dataset을 활용하여 인덱스를 입력하면 데이터를 불러오는 오브젝트를 생성합니다. \n",
    "\n",
    "그리고 생성한 dataset 오브젝트를 torch dataloader에 전달해주면, 매 학습 epoch마다 지정된 batch size의 데이터를 불러오도록 도와줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffa4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.data[:10].max(),training_data.data[:10].min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 클래스의 목표는 하나입니다. \n",
    "# 파이토치 학습 프레임워크에서 데이터에 존재할 수 있는 특정 인덱스를 호출했을 때, 인덱스에 해당하는 데이터들을 리턴하는 것 입니다. \n",
    "# 불러온 데이터들은 모델의 입출력에 맞는 데이터를 불러와야 합니다. \n",
    "\n",
    "# DNN 코드에서 일부분 수정되었습니다. \n",
    "\n",
    "class custom_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, training = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._X = data.data.unsqueeze(1)\n",
    "        self._training = training\n",
    "        \n",
    "        if self._training:\n",
    "            self._Y = data.targets\n",
    "\n",
    "        self._X = self.transforms(self._X)\n",
    "            \n",
    "    @staticmethod\n",
    "    def transforms(x):\n",
    "        return x / 255\n",
    "    \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self._training:\n",
    "            return self._X[idx], self._Y[idx]\n",
    "        else:\n",
    "            return self._X[idx]\n",
    "\n",
    "# Pytorch lightning은 pytorch 과정에서 항상 똑같이 반복되는 코드들을 사용자가 작성하지 않도록 도와줌으로써 피로도를 감소시킵니다. \n",
    "# Pytorch lightning datamodule 클래스를 활용하여, torch dataloader가 lightning에서 사용할 수 있도록 호환시킬 수 있습니다.\n",
    "\n",
    "        \n",
    "class pl_datamodule(pl.LightningDataModule):\n",
    "    def __init__(self, train, valid, batch_size = 64):\n",
    "        super().__init__()\n",
    "        self._train = train\n",
    "        self._valid = valid\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "                     \n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = custom_dataset(self._train)\n",
    "            self.valid_dataset = custom_dataset(self._valid)\n",
    "\n",
    "        elif stage == \"test\" or stage is None:\n",
    "            pass\n",
    "                     \n",
    "                     \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, batch_size = self._batch_size, shuffle = True, num_workers = 12)\n",
    "                     \n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.valid_dataset, batch_size = self._batch_size, shuffle = False, num_workers = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa5aa5",
   "metadata": {},
   "source": [
    "## 01-02. Pytorch Model\n",
    "\n",
    "아래 이미지를 처리하는 모델에는 이전 코드와 두가지 다른 layer가 활용됩니다. \n",
    "\n",
    "    1. Convolution layer\n",
    "    2. Maxpooling layer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a852f5a",
   "metadata": {},
   "source": [
    "<img src = https://imgur.com/27Ovfzt.png width = 600>\n",
    "\n",
    "<center><b> 1. Convolution Layer </b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ffdf58",
   "metadata": {},
   "source": [
    "<img src = https://imgur.com/mmEw8c0.png width = 600>\n",
    "<center><b> 2. Maxpooling Layer </b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb314b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_model(pl.LightningModule):\n",
    "    def __init__(self, dims, lr = 1e-3, device = None):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.input_dims = dims[:-1]\n",
    "        self.output_dims = dims[1:]\n",
    "        self.dims_flag = [False] * (len(self.input_dims) - 1) + [True]\n",
    "        self._lr = lr\n",
    "        \n",
    "        self.build_model()\n",
    "        \n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.acc_fn = torchmetrics.Accuracy(num_classes = dims[-1])\n",
    "        self.auc_fn = torchmetrics.AUROC(num_classes = dims[-1])\n",
    "        self.f1_fn = torchmetrics.F1Score(num_classes = dims[-1], average = 'macro')\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), self._lr)\n",
    "\n",
    "    \n",
    "    def build_block(self, i, o, output_flag = False):\n",
    "        if output_flag:\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Flatten(),\n",
    "                torch.nn.Linear(i,o),\n",
    "            )\n",
    "        else:\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(i, o, kernel_size = 3, padding = 'same'),\n",
    "                torch.nn.MaxPool2d(kernel_size = 2),\n",
    "#                 torch.nn.BatchNorm1d(o),\n",
    "                torch.nn.ReLU(),\n",
    "#                 torch.nn.Dropout(),\n",
    "            )\n",
    "    \n",
    "    \n",
    "    def build_model(self):\n",
    "        nets = []\n",
    "        for i,o,f in zip(self.input_dims, self.output_dims, self.dims_flag):\n",
    "            print(i,o,f)\n",
    "            nets.append(self.build_block(i,o,f))\n",
    "        self.net = torch.nn.ModuleList(nets)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.net:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        acc = self.acc_fn(y_hat, y)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        auc = self.auc_fn(y_hat, y)\n",
    "        self.log('train_auc', auc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        f1 = self.f1_fn(y_hat, y)\n",
    "        self.log('train_f1_macro', f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "            \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        acc = self.acc_fn(y_hat, y)\n",
    "        self.log('valid_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        auc = self.auc_fn(y_hat, y)\n",
    "        self.log('valid_auc', auc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        f1 = self.f1_fn(y_hat, y)\n",
    "        self.log('valid_f1_macro', f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        return self.extract_feature(batch[0])\n",
    "        \n",
    "    \n",
    "    def extract_feature(self, x):\n",
    "        feature_list = []\n",
    "        for l in self.net:\n",
    "            x = l(x)\n",
    "            feature_list.append(x)\n",
    "        return feature_list[-1], feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e205377",
   "metadata": {},
   "source": [
    "## 02-01. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [1,8,8,8,8,10]\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6154ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM = pl_datamodule(training_data, test_data, 512)\n",
    "DM.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pl_model(dims)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=[0],\n",
    "    max_epochs=10,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "trainer.fit(model, DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa7a70",
   "metadata": {},
   "source": [
    "## 02-02. Summary to the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_file_loader import EventFileLoader\n",
    "from glob import glob\n",
    "\n",
    "numb_logs = len(glob(os.path.join('.','lightning_logs','*'))) - 1\n",
    "\n",
    "log_path = glob(os.path.join('.','lightning_logs', f'version_{numb_logs}', 'events*'))[0]\n",
    "\n",
    "load_logs = EventFileLoader(log_path)\n",
    "\n",
    "load_logs = [i for i in load_logs.Load()]\n",
    "\n",
    "def tag_parser(log):\n",
    "    try:\n",
    "        tag = log.summary.value[0].tag\n",
    "        value = log.summary.value[0].tensor.float_val[0]\n",
    "        return tag, value\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "logger = dict()\n",
    "for log in load_logs[1:]:\n",
    "    key, value = tag_parser(log)\n",
    "    if key not in logger.keys():\n",
    "        logger[key] = [value]\n",
    "    else:\n",
    "        logger[key].append(value)\n",
    "else:\n",
    "    logger['epoch'] = logger['epoch'][::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c2428",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4,1,figsize = (10, 6), sharex = True)\n",
    "ax[0].plot(logger['epoch'], logger['train_loss'])\n",
    "ax[0].plot(logger['epoch'], logger['valid_loss'])\n",
    "argmin_loss = np.argmin(logger['valid_loss'])\n",
    "ax[0].plot(argmin_loss, logger['valid_loss'][argmin_loss],'xr')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend(['Train','Validation'])\n",
    "\n",
    "ax[1].plot(logger['epoch'], logger['train_acc'])\n",
    "ax[1].plot(logger['epoch'], logger['valid_acc'])\n",
    "argmax_acc = np.argmax(logger['valid_acc'])\n",
    "ax[1].plot(argmax_acc, logger['valid_acc'][argmax_acc],'xr')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].legend(['Train','Validation'])\n",
    "\n",
    "ax[2].plot(logger['epoch'], logger['train_auc'])\n",
    "ax[2].plot(logger['epoch'], logger['valid_auc'])\n",
    "argmax_auc = np.argmax(logger['valid_auc'])\n",
    "ax[2].plot(argmax_auc, logger['valid_auc'][argmax_auc],'xr')\n",
    "ax[2].set_ylabel('AUROC')\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].legend(['Train','Validation'])\n",
    "\n",
    "ax[3].plot(logger['epoch'], logger['train_f1_macro'])\n",
    "ax[3].plot(logger['epoch'], logger['valid_f1_macro'])\n",
    "argmax_f1_macro = np.argmax(logger['valid_f1_macro'])\n",
    "ax[3].plot(argmax_f1_macro, logger['valid_f1_macro'][argmax_f1_macro],'xr')\n",
    "ax[3].set_ylabel('F1 macro')\n",
    "ax[3].set_xlabel('Epochs')\n",
    "ax[3].legend(['Train','Validation'])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8818f3",
   "metadata": {},
   "source": [
    "## 02-03. Illustrate to the extratec feature maps by each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for bidx, b in enumerate(DM.val_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        logits, features = model.predict_step(b, bidx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.shape for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586692fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 101\n",
    "\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "fig, axes = plt.subplots(3, 8, figsize = (32, 12))\n",
    "for nl, (ax, flist) in enumerate(zip(axes, features), 1):\n",
    "    for n, col_ax in enumerate(ax):\n",
    "        col_ax.imshow(flist[sample_number, n])\n",
    "        if n == 0:\n",
    "            col_ax.set_ylabel(f'Conv Layer Number: {nl}')\n",
    "            \n",
    "fig.tight_layout()\n",
    "            \n",
    "fig,ax = plt.subplots(figsize = (32, 4))\n",
    "ax.bar(x = [f'Filter {n}' for n in range(1,9)], height = features[-2][sample_number].squeeze())\n",
    "ax.set_ylabel(f'Last Linear Layer weight')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ddd09a61b2c7e17c2a62d168de822f4c67e18302d8919811a53cdcb291e5f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
