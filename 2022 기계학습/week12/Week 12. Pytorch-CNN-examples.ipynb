{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf3a068",
   "metadata": {},
   "source": [
    "# 01. Vary types of the Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99abb0f",
   "metadata": {},
   "source": [
    "<img src = https://imgur.com/s4HMZ3V.png width = 700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65a8cc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src = https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/120px-PyTorch_logo_black.svg.png width = 150>\n",
    "\n",
    "[PyTorch](https://en.wikipedia.org/wiki/PyTorch) is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella.  \n",
    "\n",
    "It is free and open-source software released under the modified BSD license.  \n",
    "\n",
    "Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.\n",
    "\n",
    "[Installation Guide](https://pytorch.org/get-started/previous-versions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ad4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cedbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ac0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.MNIST(\n",
    "    root=\".\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\".\",\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe0abb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, target = training_data[4]\n",
    "plt.imshow(img)\n",
    "plt.title('Target: ' + str(target))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b3564",
   "metadata": {},
   "source": [
    "## 01-01. Pytorch dataloader\n",
    "\n",
    "Pytorch dataloader는 batch 단위의 데이터를 torch의 data type으로 관리하는 것을 도와주는 클래스입니다. \n",
    "\n",
    "먼저, torch dataset을 활용하여 인덱스를 입력하면 데이터를 불러오는 오브젝트를 생성합니다. \n",
    "\n",
    "그리고 생성한 dataset 오브젝트를 torch dataloader에 전달해주면, 매 학습 epoch마다 지정된 batch size의 데이터를 불러오도록 도와줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ffa4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(255, dtype=torch.uint8), tensor(0, dtype=torch.uint8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.data[:10].max(),training_data.data[:10].min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ef2c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595f82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 클래스의 목표는 하나입니다. \n",
    "# 파이토치 학습 프레임워크에서 데이터에 존재할 수 있는 특정 인덱스를 호출했을 때, 인덱스에 해당하는 데이터들을 리턴하는 것 입니다. \n",
    "# 불러온 데이터들은 모델의 입출력에 맞는 데이터를 불러와야 합니다. \n",
    "\n",
    "# DNN 코드에서 일부분 수정되었습니다. \n",
    "\n",
    "class custom_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, training = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._X = data.data.unsqueeze(1)\n",
    "        self._training = training\n",
    "        \n",
    "        if self._training:\n",
    "            self._Y = data.targets\n",
    "\n",
    "        self._X = self.transforms(self._X)\n",
    "            \n",
    "    @staticmethod\n",
    "    def transforms(x):\n",
    "        return x / 255\n",
    "    \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self._training:\n",
    "            return self._X[idx], self._Y[idx]\n",
    "        else:\n",
    "            return self._X[idx]\n",
    "\n",
    "# Pytorch lightning은 pytorch 과정에서 항상 똑같이 반복되는 코드들을 사용자가 작성하지 않도록 도와줌으로써 피로도를 감소시킵니다. \n",
    "# Pytorch lightning datamodule 클래스를 활용하여, torch dataloader가 lightning에서 사용할 수 있도록 호환시킬 수 있습니다.\n",
    "\n",
    "        \n",
    "class pl_datamodule(pl.LightningDataModule):\n",
    "    def __init__(self, train, valid, batch_size = 64):\n",
    "        super().__init__()\n",
    "        self._train = train\n",
    "        self._valid = valid\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "                     \n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = custom_dataset(self._train)\n",
    "            self.valid_dataset = custom_dataset(self._valid)\n",
    "\n",
    "        elif stage == \"test\" or stage is None:\n",
    "            pass\n",
    "                     \n",
    "                     \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, batch_size = self._batch_size, shuffle = True, num_workers = 12)\n",
    "                     \n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.valid_dataset, batch_size = self._batch_size, shuffle = False, num_workers = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa5aa5",
   "metadata": {},
   "source": [
    "## 01-02. Pytorch Model\n",
    "\n",
    "아래 이미지를 처리하는 모델에는 이전 코드와 두가지 다른 layer가 활용됩니다. \n",
    "\n",
    "    1. Convolution layer\n",
    "    2. Maxpooling layer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a852f5a",
   "metadata": {},
   "source": [
    "<img src = https://imgur.com/27Ovfzt.png width = 600>\n",
    "\n",
    "<center><b> 1. Convolution Layer </b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ffdf58",
   "metadata": {},
   "source": [
    "<img src = https://imgur.com/mmEw8c0.png width = 600>\n",
    "<center><b> 2. Maxpooling Layer </b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb314b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_model(pl.LightningModule):\n",
    "    def __init__(self, dims, lr = 1e-3, device = None):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.input_dims = dims[:-1]\n",
    "        self.output_dims = dims[1:]\n",
    "        self.dims_flag = [False] * (len(self.input_dims) - 1) + [True]\n",
    "        self._lr = lr\n",
    "        \n",
    "        self.build_model()\n",
    "        \n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.acc_fn = torchmetrics.Accuracy(num_classes = dims[-1])\n",
    "        self.auc_fn = torchmetrics.AUROC(num_classes = dims[-1])\n",
    "        self.f1_fn = torchmetrics.F1Score(num_classes = dims[-1], average = 'macro')\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), self._lr)\n",
    "\n",
    "    \n",
    "    def build_block(self, i, o, output_flag = False):\n",
    "        if output_flag:\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Flatten(),\n",
    "                torch.nn.Linear(i,o),\n",
    "            )\n",
    "        else:\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(i, o, kernel_size = 3, padding = 'same'),\n",
    "                torch.nn.MaxPool2d(kernel_size = 2),\n",
    "#                 torch.nn.BatchNorm1d(o),\n",
    "                torch.nn.ReLU(),\n",
    "#                 torch.nn.Dropout(),\n",
    "            )\n",
    "    \n",
    "    \n",
    "    def build_model(self):\n",
    "        nets = []\n",
    "        for i,o,f in zip(self.input_dims, self.output_dims, self.dims_flag):\n",
    "            print(i,o,f)\n",
    "            nets.append(self.build_block(i,o,f))\n",
    "        self.net = torch.nn.ModuleList(nets)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.net:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        acc = self.acc_fn(y_hat, y)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        auc = self.auc_fn(y_hat, y)\n",
    "        self.log('train_auc', auc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        f1 = self.f1_fn(y_hat, y)\n",
    "        self.log('train_f1_macro', f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "            \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        acc = self.acc_fn(y_hat, y)\n",
    "        self.log('valid_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        auc = self.auc_fn(y_hat, y)\n",
    "        self.log('valid_auc', auc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        f1 = self.f1_fn(y_hat, y)\n",
    "        self.log('valid_f1_macro', f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        return self.extract_feature(batch[0])\n",
    "        \n",
    "    \n",
    "    def extract_feature(self, x):\n",
    "        feature_list = []\n",
    "        for l in self.net:\n",
    "            x = l(x)\n",
    "            feature_list.append(x)\n",
    "        return feature_list[-1], feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e205377",
   "metadata": {},
   "source": [
    "## 02-01. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec3ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 8, 8, 8, 10]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = [1,8,8,8,8,10]\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6154ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM = pl_datamodule(training_data, test_data, 512)\n",
    "DM.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca1e2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 8 False\n",
      "8 8 False\n",
      "8 8 False\n",
      "8 8 False\n",
      "8 10 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | net     | ModuleList       | 1.9 K \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "2 | acc_fn  | Accuracy         | 0     \n",
      "3 | auc_fn  | AUROC            | 0     \n",
      "4 | f1_fn   | F1Score          | 0     \n",
      "---------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\keb20\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:563: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 2600, 18832, 3308, 16188, 9568, 21468, 15840, 20192, 21808, 24416, 18120, 8752) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8784/1521522984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"`Trainer.fit()` requires a `LightningModule`, got: {model.__class__.__qualname__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[0;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         )\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;31m# enable train mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;31m# run eval step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m                 \u001b[0mval_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_sanity_check_end\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dataloader_idx\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mdl_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;31m# store batch level output per dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataLoaderIterDataFetcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mbatch_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetching_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py\u001b[0m in \u001b[0;36mfetching_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m                 \u001b[1;31m# consume the batch we just fetched\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py\u001b[0m in \u001b[0;36m_fetch_next_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mstart_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_fetch_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop_profiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1323\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1325\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\keb20\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2600, 18832, 3308, 16188, 9568, 21468, 15840, 20192, 21808, 24416, 18120, 8752) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "model = pl_model(dims)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    # accelerator='gpu', \n",
    "    # devices=[0],\n",
    "    max_epochs=10,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "trainer.fit(model, DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa7a70",
   "metadata": {},
   "source": [
    "## 02-02. Summary to the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_file_loader import EventFileLoader\n",
    "from glob import glob\n",
    "\n",
    "numb_logs = len(glob(os.path.join('.','lightning_logs','*'))) - 1\n",
    "\n",
    "log_path = glob(os.path.join('.','lightning_logs', f'version_{numb_logs}', 'events*'))[0]\n",
    "\n",
    "load_logs = EventFileLoader(log_path)\n",
    "\n",
    "load_logs = [i for i in load_logs.Load()]\n",
    "\n",
    "def tag_parser(log):\n",
    "    try:\n",
    "        tag = log.summary.value[0].tag\n",
    "        value = log.summary.value[0].tensor.float_val[0]\n",
    "        return tag, value\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "logger = dict()\n",
    "for log in load_logs[1:]:\n",
    "    key, value = tag_parser(log)\n",
    "    if key not in logger.keys():\n",
    "        logger[key] = [value]\n",
    "    else:\n",
    "        logger[key].append(value)\n",
    "else:\n",
    "    logger['epoch'] = logger['epoch'][::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c2428",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4,1,figsize = (10, 6), sharex = True)\n",
    "ax[0].plot(logger['epoch'], logger['train_loss'])\n",
    "ax[0].plot(logger['epoch'], logger['valid_loss'])\n",
    "argmin_loss = np.argmin(logger['valid_loss'])\n",
    "ax[0].plot(argmin_loss, logger['valid_loss'][argmin_loss],'xr')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend(['Train','Validation'])\n",
    "\n",
    "ax[1].plot(logger['epoch'], logger['train_acc'])\n",
    "ax[1].plot(logger['epoch'], logger['valid_acc'])\n",
    "argmax_acc = np.argmax(logger['valid_acc'])\n",
    "ax[1].plot(argmax_acc, logger['valid_acc'][argmax_acc],'xr')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].legend(['Train','Validation'])\n",
    "\n",
    "ax[2].plot(logger['epoch'], logger['train_auc'])\n",
    "ax[2].plot(logger['epoch'], logger['valid_auc'])\n",
    "argmax_auc = np.argmax(logger['valid_auc'])\n",
    "ax[2].plot(argmax_auc, logger['valid_auc'][argmax_auc],'xr')\n",
    "ax[2].set_ylabel('AUROC')\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].legend(['Train','Validation'])\n",
    "\n",
    "ax[3].plot(logger['epoch'], logger['train_f1_macro'])\n",
    "ax[3].plot(logger['epoch'], logger['valid_f1_macro'])\n",
    "argmax_f1_macro = np.argmax(logger['valid_f1_macro'])\n",
    "ax[3].plot(argmax_f1_macro, logger['valid_f1_macro'][argmax_f1_macro],'xr')\n",
    "ax[3].set_ylabel('F1 macro')\n",
    "ax[3].set_xlabel('Epochs')\n",
    "ax[3].legend(['Train','Validation'])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8818f3",
   "metadata": {},
   "source": [
    "## 02-03. Illustrate to the extratec feature maps by each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for bidx, b in enumerate(DM.val_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        logits, features = model.predict_step(b, bidx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.shape for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586692fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 101\n",
    "\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "fig, axes = plt.subplots(3, 8, figsize = (32, 12))\n",
    "for nl, (ax, flist) in enumerate(zip(axes, features), 1):\n",
    "    for n, col_ax in enumerate(ax):\n",
    "        col_ax.imshow(flist[sample_number, n])\n",
    "        if n == 0:\n",
    "            col_ax.set_ylabel(f'Conv Layer Number: {nl}')\n",
    "            \n",
    "fig.tight_layout()\n",
    "            \n",
    "fig,ax = plt.subplots(figsize = (32, 4))\n",
    "ax.bar(x = [f'Filter {n}' for n in range(1,9)], height = features[-2][sample_number].squeeze())\n",
    "ax.set_ylabel(f'Last Linear Layer weight')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ddd09a61b2c7e17c2a62d168de822f4c67e18302d8919811a53cdcb291e5f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
