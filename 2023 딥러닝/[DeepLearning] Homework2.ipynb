{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4oB0TgoPK3V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# FMNIST 데이터셋 로드\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# 픽셀 값 정규화\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# 모델 구조 정의\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(x_train.reshape(-1, 28, 28, 1), y_train, \n",
        "                    epochs=10, \n",
        "                    validation_data=(x_test.reshape(-1, 28, 28, 1), y_test))\n",
        "\n",
        "# 학습/검증 손실 출력\n",
        "print(\"Train loss:\", history.history['loss'][-1])\n",
        "print(\"Validation loss:\", history.history['val_loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 레이어 정의\n",
        "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "# 컨볼루션 레이어 정의\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "\n",
        "# 완전 연결 레이어 정의\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "\n",
        "# 모델 정의\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(x_train.reshape(-1, 28, 28, 1), y_train, \n",
        "                    epochs=10, \n",
        "                    validation_data=(x_test.reshape(-1, 28, 28, 1), y_test))\n",
        "\n",
        "# 학습/검증\n",
        "print(\"Train loss:\", history.history['loss'][-1])\n",
        "print(\"Validation loss:\", history.history['val_loss'][-1])"
      ],
      "metadata": {
        "id": "CSkfm9ACGdfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# CIFAR10 데이터셋 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Sequential API를 사용한 모델\n",
        "model_seq = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_seq.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_seq = model_seq.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
        "\n",
        "# Functional API를 사용한 모델\n",
        "inputs = Input(shape=(32,32,3))\n",
        "x = Conv2D(32, (3,3), activation='relu')(inputs)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_func = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model_func.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_func = model_func.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
        "\n",
        "# 학습/검증 손실 출력\n",
        "print(\"Sequential API 모델\")\n",
        "print(\"Train loss:\", history_seq.history['loss'][-1])\n",
        "print(\"Validation loss:\", history_seq.history['val_loss'][-1])\n",
        "\n",
        "print(\"\\nFunctional API 모델\")\n",
        "print(\"Train loss:\", history_func.history['loss'][-1])\n",
        "print(\"Validation loss:\", history_func.history['val_loss'][-1]))"
      ],
      "metadata": {
        "id": "iQNgChIgxICx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# CIFAR10 데이터셋 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# 사전 학습된 ResNet50 모델 로드\n",
        "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "\n",
        "# ResNet50 모델의 일부 층을 동결\n",
        "for layer in resnet.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 전이 학습 모델 정의\n",
        "model = Sequential([\n",
        "    resnet,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료를 위한 콜백 함수\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# 학습/검증 손실 출력\n",
        "print(\"Train loss:\", history.history['loss'][-1])\n",
        "print(\"Validation loss:\", history.history['val_loss'][-1])"
      ],
      "metadata": {
        "id": "Y8HHQPUhxL1r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}